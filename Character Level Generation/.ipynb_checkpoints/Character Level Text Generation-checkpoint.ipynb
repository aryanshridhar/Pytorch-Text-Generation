{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import PyPDF2\n",
    "from nltk.corpus import stopwords\n",
    "import unidecode\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "all_chars = string.printable\n",
    "print(all_chars)\n",
    "print(len(all_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PdfToText: # extracts text from the pdf file\n",
    "    \n",
    "#     def __init__(self , pdf):\n",
    "        \n",
    "#         self.text = ''\n",
    "        \n",
    "#         pdf_file = open(pdf , 'rb')\n",
    "#         read_pdf = PyPDF2.PdfFileReader(pdf_file , strict = False)\n",
    "#         number_of_pages = read_pdf.getNumPages()\n",
    "#         for i in range(number_of_pages):\n",
    "#             page = read_pdf.getPage(i)\n",
    "#             page_content = page.extractText()\n",
    "            \n",
    "#             self.text += page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data.txt') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776697"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessing:\n",
    "    def __init__(self , text):\n",
    "        self.text = text\n",
    "        self.text = unidecode.unidecode(self.text)\n",
    "        self.text = re.sub(' +',' ', self.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = TextPreprocessing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = t1.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_dup(seq): # Removes duplicate words from the dataset passed\n",
    "#     seen = set()\n",
    "#     seen_add = seen.add\n",
    "#     return [x for x in seq if not (x in seen or seen_add(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \" \".join(remove_dup(nltk.word_tokenize(t1.text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharGenRNN(nn.Module):\n",
    "    def __init__(self , input_size , hidden_size , output_size , n_layers):\n",
    "        \n",
    "        super(CharGenRNN , self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
    "        self.rnn = nn.LSTM(self.hidden_size , \n",
    "                           self.hidden_size , \n",
    "                           self.n_layers , \n",
    "                           batch_first = True)\n",
    "        self.linear = nn.Linear(self.hidden_size , self.output_size)\n",
    "   \n",
    "    def forward(self , batch):\n",
    "        batch = batch.long()\n",
    "        out = self.embedding(batch)\n",
    "        out , _ = self.rnn(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generation:\n",
    "    def __init__(self , text , all_chars):\n",
    "        \n",
    "        self.seq_len = 256 # predicting next character form the previous 32 characters\n",
    "        self.batch_size = 126 # total of 16 , 32 seq in a batch\n",
    "        \n",
    "        self.all_chars = {j:i for i,j in enumerate(all_chars)}\n",
    "        self.reverse_chars = {i:j for i,j in enumerate(all_chars)}\n",
    "        \n",
    "        self.text = text[:-(len(text) % (self.seq_len * self.batch_size))]\n",
    "\n",
    "        self.input_size = len(all_chars)\n",
    "        self.hidden_size = 256\n",
    "        self.output_size = self.input_size\n",
    "        self.n_layers = 1\n",
    "        self.epochs = 1000\n",
    "        self.print_every = 10\n",
    "        self.generate_every = 50\n",
    "        self.lr = 0.05\n",
    "        \n",
    "        self.rnn = CharGenRNN(self.input_size , \n",
    "                              self.hidden_size , \n",
    "                              self.output_size , \n",
    "                              self.n_layers).to(device)\n",
    "        \n",
    "\n",
    "    def get_batches(self):\n",
    "        \n",
    "        i = 0\n",
    "        counter = 0    \n",
    "        no_time = len(self.text) // (self.seq_len * self.batch_size)\n",
    "        encoded_text = list(map(lambda x : self.all_chars[x] , self.text))\n",
    "        \n",
    "        while i != int(no_time)-1:\n",
    "            \n",
    "            x_list = []\n",
    "            y_seq = []\n",
    "            \n",
    "            for _ in range(self.batch_size):\n",
    "                x_list.append(encoded_text[counter:self.seq_len+counter])\n",
    "                y_seq.append(encoded_text[counter + 1:self.seq_len+counter+1])\n",
    "                counter += self.seq_len\n",
    "            \n",
    "            i += 1\n",
    "            yield x_list,y_seq\n",
    "            \n",
    "            \n",
    "    def show_batches(self):\n",
    "        for i,j in self.get_batches():\n",
    "            i , j = torch.Tensor(i).long() , torch.Tensor(j).long()\n",
    "            print(i)\n",
    "            print(j)\n",
    "            break\n",
    "            \n",
    "    def init_loss(self):\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            for label,actual in self.get_batches():\n",
    "                    \n",
    "                label = torch.Tensor(label).float().to(device)\n",
    "                actual = torch.Tensor(actual).long().to(device)\n",
    "            \n",
    "                y_pred = self.rnn(label)\n",
    "                y_pred = y_pred.transpose(1,2)\n",
    "                loss = self.criterion(y_pred,actual)\n",
    "                \n",
    "                print(loss.item())\n",
    "                break\n",
    "            break\n",
    "            \n",
    "    def train(self):\n",
    "        \n",
    "        time1 = time.time()\n",
    "        \n",
    "        self.iterations = []\n",
    "        self.loss_ = []\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.optimizer = optim.SGD(self.rnn.parameters() , lr = self.lr)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            for label,actual in self.get_batches():\n",
    "\n",
    "                    \n",
    "                label = torch.Tensor(label).float().to(device)\n",
    "                actual = torch.Tensor(actual).long().to(device)\n",
    "            \n",
    "                y_pred = self.rnn(label)\n",
    "                y_pred = y_pred.transpose(1,2)\n",
    "                \n",
    "                loss = self.criterion(y_pred,actual)\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    \n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "                    \n",
    "            self.iterations.append(epoch)\n",
    "            self.loss_.append(loss)\n",
    "            \n",
    "            if epoch % self.print_every == 0:\n",
    "                print(f\"Loss after {epoch} iteration : {loss}\")\n",
    "                \n",
    "            if epoch % self.generate_every == 0:\n",
    "                final = time.time() - time1\n",
    "                print(f\"Time elapsed : {final}\\n\")\n",
    "                print(f\"Generated Text after {epoch} epoch : {self.generate_text()}\\n\")\n",
    "                \n",
    "                \n",
    "        self.show_plot(self.iterations , self.loss_)\n",
    "                \n",
    "                \n",
    "    def show_plot(self,x,y):\n",
    "        plt.plot(x,y)\n",
    "        plt.xlabel('Epoch/Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def generate_text(self , init_str = 'Hello Everybody , I am ',predict_len = 200):\n",
    "        \n",
    "        generated_list = [w for w in init_str]\n",
    "        \n",
    "        for _ in range(predict_len):\n",
    "            \n",
    "            tensor = torch.Tensor([self.all_chars[generated_list[-1].lower()]]).long().unsqueeze(0)\n",
    "            out = self.rnn(tensor.to(device))\n",
    "            prob = F.softmax(out.squeeze() , dim = 0)\n",
    "            \n",
    "            value , ind = torch.topk(prob , 3)\n",
    "            index = np.random.choice(ind.tolist())\n",
    "    \n",
    "            char = self.reverse_chars[index]\n",
    "            \n",
    "            generated_list.append(char)\n",
    "            \n",
    "        return ''.join(generated_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = Generation(text , all_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[55, 17, 14,  ..., 14, 27, 16],\n",
      "        [94, 47, 18,  ...,  8, 96, 96],\n",
      "        [47, 10, 23,  ..., 27, 28, 29],\n",
      "        ...,\n",
      "        [23, 13, 96,  ..., 24, 25, 21],\n",
      "        [14, 78, 94,  ..., 73, 94, 10],\n",
      "        [28, 94, 17,  ..., 10, 23, 20]])\n",
      "tensor([[17, 14, 94,  ..., 27, 16, 94],\n",
      "        [47, 18, 12,  ..., 96, 96, 47],\n",
      "        [10, 23, 16,  ..., 28, 29, 74],\n",
      "        ...,\n",
      "        [13, 96, 27,  ..., 25, 21, 14],\n",
      "        [78, 94, 10,  ..., 94, 10, 28],\n",
      "        [94, 17, 14,  ..., 23, 20, 94]])\n"
     ]
    }
   ],
   "source": [
    "g1.show_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.621908664703369\n"
     ]
    }
   ],
   "source": [
    "g1.init_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 0 iteration : 4.385647296905518\n",
      "5.490497827529907\n",
      "Hello Everybody , I am nd hse n  n ndssen hser. hsennndsennnd     nds h n  h nder he nnde nnnds n n n  nnd n n nd nde nnn h   ndendssser.  nnde  nnnd nnd  h h hs hs ndersss hse  hsend n nnnn nd   nnn nndss hs  nn  h   her  \n",
      "10.848368883132935\n",
      "Hello Everybody , I am t t tee haeer t h t heeere  t h that h tee h heerth h the teer t   haerer t ter t h  haerer the ther heert  tha   he tha hathaer  th t  ha hae thae ha t ha ha hee  ha h h haee h terereeeertert tert h \n",
      "16.172104358673096\n",
      "Hello Everybody , I am at thater tere ae aerter t te t t t therter thert aerte a ate aee t athat t a a    a  teeeer a ae a  ath ae a atereere tha   te  t   aee  th ate  t tee a    te at a   atee  a aert ae the  t ate teeer \n",
      "21.688166618347168\n",
      "Hello Everybody , I am th a h t a aeerter a a h atee t a aerthathath thae t the te atee at aerert ae aeertha a h at a hat ath h heerth the t hateert ther hee a t haereeerertereere teer thaeree te t atha tha aeert a tha he t\n",
      "26.92687964439392\n",
      "Hello Everybody , I am t t te a herereee at atere at ane t a he heereereeeree h t hane theeer th the tera atereer a a hereerate h her athaneer haneereerer herathaterath he ande theer t anera an tha ha at he a ate ane atee t\n",
      "32.06743884086609\n",
      "Hello Everybody , I am h a thatend tendene t handrerat and h atera h he at h ath and he t hatendendera thand herat a a the h a h a hatera te t he a anderen t atere ath ha ten atendr h he at a h a hen hathe a ath h h hen t a\n",
      "37.460681200027466\n",
      "Hello Everybody , I am a h andre te h an hanen han an ha t herat th hend h here the t he h ate hat t at ten ten t her t ath haten h t therend h h aner ath he a he h a a h anenen heranerer heren th h th at hatha hanend at an\n"
     ]
    }
   ],
   "source": [
    "g1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g1.generate_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
